chicago <- get_acs(
geography = "block group"
year = 2019,
chicago <- get_acs(
geography = "block group",
year = 2019,
state = 17,
county = "cook",
survey = "acs5",
)
chicago <- get_acs(
geography = "block group",
variables = c("B01003", "B02001")
year = 2019,
chicago <- get_acs(
geography = "block group",
variables = c("B01003", "B02001"),
year = 2019,
state = 17,
county = "cook",
survey = "acs5",
)
chicago <- get_acs(
geography = "block group",
variables = c("B01003_001", "B02001_001"),
year = 2019,
state = 17,
county = "cook",
survey = "acs5",
)
View(chicago)
cook_county_bg <- get_acs(
geography = "block group",
variables = c("B01003_001", "B02001_001"),
year = 2019,
state = 17,
county = "cook",
survey = "acs5",
)
chicago <- places("IL", cb = TRUE) |>
filter(NAME %in% "Chicago")
View(chicago)
install.packages("rgeos")
View(cook_county_bg)
library(tidyverse)
library(stargazer)
library(hrbrthemes)
hrbrthemes::import_roboto_condensed()
hrbrthemes::import_arial_narrow()
Row <- c(1:4)
Recommended_Protocol_Changes <- c("More detailed status updates", "Official classroom control procedures", "More information about safety best practices", "Emergency protocols incorporated into orientation")
library(tidyverse)
library(tidyverse)
library(tidyverse)
trees <- read_csv("C:\Users\devin\OneDrive\Documents\Course_Work\GEOG_370\HW1\DATA\Tree_Inventory_20240119.csv")
library(jsonlite)
install.package("igraph")
install.packages("igraph")
install.package("ggraph")
install.packages("ggraph")
install.packages("tidygraph")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
# Chunk 2: libraries
library(tidyverse)
library(igraph)
library(ggraph)
library(tidygraph)
# Chunk 3
ISR_2016 <- read_csv("../data/ISR-2016.csv")
install.packages("spatstat")
?spatstat
library(spatstat)
beginner
help.start
getstart
vignette('getstart')
install.packages("bartMachine")
install.packages("bartMachine")
install.packages(c("arcpullr", "BH", "bookdown", "brew", "brio", "bslib", "callr", "checkmate", "cli", "coda", "commonmark", "countrycode", "cowplot", "crul", "curl", "data.table", "datawizard", "DBI", "dbplyr", "deldir", "desc", "digest", "dslabs", "DT", "fansi", "filelock", "gdtools", "geometries", "gert", "ggeffects", "ggforce", "ggiraph", "ggnetwork", "ggplot2", "ggraph", "ggrepel", "ggsci", "ggstance", "ggthemes", "gh", "glue", "graphlayouts", "haven", "Hmisc", "hrbrthemes", "htmltools", "httpuv", "httr2", "huxtable", "idbr", "igraph", "insight", "intergraph", "interp", "ISOcodes", "jqr", "kableExtra", "keyring", "knitr", "later", "lattice", "leaflet", "lme4", "lwgeom", "maps", "markdown", "MASS", "Matrix", "munsell", "patchwork", "pkgbuild", "pkgdown", "pkgload", "plotly", "prettymapr", "processx", "progress", "PROJ", "proj4", "promises", "ps", "psych", "quanteda", "R.oo", "ragg", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "readr", "remotes", "renv", "repr", "reprex", "rlang", "rmarkdown", "rnaturalearth", "rnaturalearthdata", "roxygen2", "rsconnect", "rstudioapi", "rvest", "s2", "sass", "servr", "sf", "sfheaders", "shiny", "shinyWidgets", "sp", "spatstat", "spatstat.explore", "spatstat.geom", "spatstat.linnet", "spatstat.model", "spatstat.random", "spdep", "stars", "stringi", "survival", "svglite", "systemfonts", "terra", "testthat", "textshape", "thematic", "tidycensus", "tidyr", "tidyselect", "tidytext", "tigris", "timechange", "timeDate", "timeSeries", "tinytex", "tm", "tweenr", "usethis", "usmap", "usmapdata", "uuid", "V8", "viridis", "vroom", "withr", "writexl", "xfun", "XML", "xml2", "yaml", "zip"))
library(stargazer)
# Chunk 1: libraries
#ensure code folds
knitr::opts_chunk$set(class.source = "foldable")
options(scipen = 999)
#load libraries
library(tidyverse)
library(sf)
library(tmap)
tmap_mode(mode = "plot")
library(lubridate)
#library(tidycensus)
#library(tigris)
library(here)
library(stargazer)
# Chunk 2
#Get Median Home Values
# MEDIAN_HOMEVALUE <- get_acs(
#   state = '17',
#   county = '031',
#   geography = "block group",
#   variables = "B25077_001",
#   geometry = TRUE,
#   year = 2022
# ) |>
#   rename(
#     MEDIAN_HOME_VALUE  = "estimate",
#     MHV_MOE = "moe"
#   ) |>
#   select(
#     GEOID,
#     MEDIAN_HOME_VALUE,
#     MHV_MOE
# )
#
# #Get Population counts
# POPULATION <- get_acs(
#   state = '17',
#   county = '031',
#   geography = "block group",
#   variables = "B01003_001",
#   geometry = FALSE,
#   year = 2022
# ) |>
#   rename(
#     POPULATION  = "estimate",
#     POP_MOE = "moe"
#   ) |>
#   select(
#     GEOID,
#     POPULATION,
#     POP_MOE
#   )
#
# DEMOGRAPHICS <- MEDIAN_HOMEVALUE |> left_join(POPULATION, by=join_by(GEOID), keep = FALSE)
# rm(POPULATION)
# rm(MEDIAN_HOMEVALUE)
# Chunk 3
#Read in ISR data
ISR_2022 <-  here("DATA", "ISR_2022_BLOCKGROUPS.geojson") |> read_sf()
NC <- getbb(
"North Carolina",
display_name_contains = NULL,
viewbox = NULL,
format_out = "data-frame",
base_url = "https://nominatim.openstreetmap.org",
featuretype = "state",
limit = 10,
key = NULL,
silent = TRUE
))
NC <- getbb(
"North Carolina",
display_name_contains = NULL,
viewbox = NULL,
format_out = "data-frame",
base_url = "https://nominatim.openstreetmap.org",
featuretype = "state",
limit = 10,
key = NULL,
silent = TRUE
)
library(tidyverse)
library(osmdata)
```
NC <- getbb(
"North Carolina",
display_name_contains = NULL,
viewbox = NULL,
format_out = "data-frame",
base_url = "https://nominatim.openstreetmap.org",
featuretype = "state",
limit = 10,
key = NULL,
silent = TRUE
)
NC <- getbb(
"North Carolina",
display_name_contains = NULL,
viewbox = NULL,
format_out = "data.frame",
base_url = "https://nominatim.openstreetmap.org",
featuretype = "state",
limit = 10,
key = NULL,
silent = TRUE
)
HOSPITALS <- opq(bbox = NC) %>%
add_osm_feature(key = 'hospital')
View(HOSPITALS)
NC_HOSPITALS <- NC %>%
opq() %>%
add_osm_feature(key = "amenity", value = "hospital") %>%
osmdata_sf()
View(NC_HOSPITALS)
NC_HOSPITALS <- NC %>%
opq() %>%
add_osm_feature(key = "amenity", value = "hospital")
View(NC_HOSPITALS)
library(tidyverse)
library(rvest)
library(tmap)
library(RSelenium)
library(wdman)
library(netstat)
library(tidygeocoder)
library(sf)
library(ggplot2)
tmap_mode("view")
library(widgetframe)
library(purrr)
# ah-property-address params="AddressLine1: tnResultModel.domain.propertyList()[7].AddressLine1(), AddressLine2: tnResultModel.domain.propertyList()[7].AddressLine2(), City: tnResultModel.domain.propertyList()[7].City(), State: tnResultModel.domain.propertyList()[7].State(), Zip: tnResultModel.domain.propertyList()[7].Zip()"></ah-property-address>
url <- "https://www.affordablehousing.com/durham-county-nc/"
ah_html <- read_html(url) %>% html_nodes("div")
View(ah_html)
rents <-
ah_html |>
html_element('div.tnresult--propertyaddress') |>
html_text() %>%
str_replace_all("\\$|,+", "") %>% # Remove special characters
as.numeric()
rents <-
ah_html |>
html_element('div.tnresult--propertyaddress') |>
str_replace_all("\\$|,+", "") %>% # Remove special characters
as.numeric()
rents <-
ah_html |>
html_element('div.tnresult--propertyaddress') |>
as.tibble()
rents <-
ah_html |>
html_element('div.tnresult--propertyaddress') |>
as_tibble()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(tidyverse)
library(rvest)
library(tmap)
library(RSelenium)
library(wdman)
library(netstat)
# Chunk 3
lakecounty <- 'lake-county-il'
bedrooms <- 2
bathrooms <- 1
maxprice <- 1500
baseurl <- paste0("https://www.affordablehousing.com/", lakecounty, "/")
queries <- vector("character", 0)
queries[1] <- paste0("under-", maxprice)
queries[2] <-  paste0(bedrooms, "-bed")
queries[3] <- paste0(bathrooms, "-bath")
(query_url <- paste0(baseurl, paste(queries, collapse = "/"), "/"))
# Chunk 4
rD <- rsDriver(browser = 'firefox',
verbose =F,
chromever = NULL,
port = free_port())
remDr <- rD[["client"]]
remDr$navigate(query_url)
Sys.sleep(2)
html_page <- remDr$getPageSource()[[1]]
# Chunk 5
extract_rentals <- function(x) {
addresses <-
x %>%
html_element('div.tnresult--propertyaddress') %>%
html_text()
prices <-
x %>%
html_element("div.tnresult--price") %>%
html_text() %>%
str_replace_all("\\$|,+", "")
prices <- gsub("^(\\d+)-\\d+$", "\\1", prices) #Extracts the minimum rent when prices are listed in a range
prices <- as.numeric(prices)
assign("addresses", addresses, envir = .GlobalEnv)
assign("prices", prices, envir = .GlobalEnv)
}
# Chunk 6
extract_rentals2 <- function(x) {
addresses2 <-
x %>%
html_element('div.tnresult--propertyaddress') %>%
html_text()
#There are no titles for the listings
prices2 <-
x %>%
html_element("div.tnresult--price") %>%
html_text() %>%
str_replace_all("\\$|,+", "")
prices2 <- gsub("^(\\d+)-\\d+$", "\\1", prices2) #Extracts the minimum rent when prices are listed in a range
prices2 <- as.numeric(prices2)
assign("addresses2", addresses2, envir = .GlobalEnv)
assign("prices2", prices2, envir = .GlobalEnv)
}
# Chunk 7
raw_query <- read_html(html_page)
raw_ads <- html_elements(raw_query, "div.tnresult--card")
raw_ads %>% head()
extract_rentals(raw_ads)
raw_query2 <- read_html(html_page)
raw_ads2 <- html_elements(raw_query2, "div.tnresult--small--card")
raw_ads2 %>% head()
extract_rentals2(raw_ads2)
addresses <- c(addresses, addresses2)
prices <- c(prices, prices2)
laketable <- cbind(addresses, prices)
# Chunk 8
cook_pages <- c("", paste("page", 2:52, sep = "-"))
# Chunk 9
cookcounty <- 'cook-county-il'
bedrooms <- 2
bathrooms <- 1
maxprice <- 1500
queries <- vector("character", 0)
queries[1] <- paste0("under-", maxprice)
queries[2] <-  paste0(bedrooms, "-bed")
queries[3] <- paste0(bathrooms, "-bath")
cookurl <- paste0("https://www.affordablehousing.com/", cookcounty, "/")
(query_url_cook <- paste0(cookurl, paste(queries, collapse = "/"), "/"))
# Chunk 10
rD <- rsDriver(browser = 'firefox',
verbose =F,
chromever = NULL,
port = free_port())
remDr <- rD[["client"]]
remDr$navigate(query_url_cook)
Sys.sleep(2)
html_page <- remDr$getPageSource()[[1]]
# Chunk 11
raw_query <- read_html(html_page)
raw_ads <- html_elements(raw_query, "div.tnresult--card")
raw_ads %>% head()
extract_rentals(raw_ads)
raw_query2 <- read_html(html_page)
raw_ads2 <- html_elements(raw_query2, "div.tnresult--small--card")
raw_ads2 %>% head()
extract_rentals2(raw_ads2)
addresses <- c(addresses, addresses2)
prices <- c(prices, prices2)
cooktable <- cbind(addresses, prices)
# Chunk 12
dupage <- 'dupage-county-il'
bedrooms <- 2
bathrooms <- 1
maxprice <- 1500
queries <- vector("character", 0)
queries[1] <- paste0("under-", maxprice)
queries[2] <-  paste0(bedrooms, "-bed")
queries[3] <- paste0(bathrooms, "-bath")
dupageurl <- paste0("https://www.affordablehousing.com/", dupage, "/")
(query_url_dupage <- paste0(dupageurl, paste(queries, collapse = "/"), "/"))
# Chunk 13
rD <- rsDriver(browser = 'firefox',
verbose =F,
chromever = NULL,
port = free_port())
remDr <- rD[["client"]]
remDr$navigate(query_url_dupage)
Sys.sleep(2)
html_page <- remDr$getPageSource()[[1]]
# Chunk 14
raw_query <- read_html(html_page)
raw_ads <- html_elements(raw_query, "div.tnresult--card")
raw_ads %>% head()
extract_rentals(raw_ads)
raw_query2 <- read_html(html_page)
raw_ads2 <- html_elements(raw_query2, "div.tnresult--small--card")
raw_ads2 %>% head()
extract_rentals2(raw_ads2)
addresses <- c(addresses, addresses2)
prices <- c(prices, prices2)
dupagetable <- cbind(addresses, prices)
# Chunk 15
will <- 'will-county-il'
bedrooms <- 2
bathrooms <- 1
maxprice <- 1500
queries <- vector("character", 0)
queries[1] <- paste0("under-", maxprice)
queries[2] <-  paste0(bedrooms, "-bed")
queries[3] <- paste0(bathrooms, "-bath")
willurl <- paste0("https://www.affordablehousing.com/", will, "/")
(query_url_will <- paste0(willurl, paste(queries, collapse = "/"), "/"))
# Chunk 16
rD <- rsDriver(browser = 'firefox',
verbose =F,
chromever = NULL,
port = free_port())
remDr <- rD[["client"]]
remDr$navigate(query_url_will)
Sys.sleep(2)
html_page <- remDr$getPageSource()[[1]]
# Chunk 17
raw_query <- read_html(html_page)
raw_ads <- html_elements(raw_query, "div.tnresult--card")
raw_ads %>% head()
extract_rentals(raw_ads)
raw_query2 <- read_html(html_page)
raw_ads2 <- html_elements(raw_query2, "div.tnresult--small--card")
raw_ads2 %>% head()
extract_rentals2(raw_ads2)
addresses <- c(addresses, addresses2)
prices <- c(prices, prices2)
willtable <- cbind(addresses, prices)
# Chunk 18
dekalb <- 'dekalb-county-il'
bedrooms <- 2
bathrooms <- 1
maxprice <- 1500
queries <- vector("character", 0)
queries[1] <- paste0("under-", maxprice)
queries[2] <-  paste0(bedrooms, "-bed")
queries[3] <- paste0(bathrooms, "-bath")
dekalburl <- paste0("https://www.affordablehousing.com/", dekalb, "/")
(query_url_dekalb <- paste0(dekalburl, paste(queries, collapse = "/"), "/"))
# Chunk 19
rD <- rsDriver(browser = 'firefox',
verbose =F,
chromever = NULL,
port = free_port())
remDr <- rD[["client"]]
remDr$navigate(query_url_dekalb)
Sys.sleep(2)
html_page <- remDr$getPageSource()[[1]]
# Chunk 20
raw_query <- read_html(html_page)
raw_ads <- html_elements(raw_query, "div.tnresult--card")
raw_ads %>% head()
extract_rentals(raw_ads)
raw_query2 <- read_html(html_page)
raw_ads2 <- html_elements(raw_query2, "div.tnresult--small--card")
raw_ads2 %>% head()
extract_rentals2(raw_ads2)
addresses <- c(addresses, addresses2)
prices <- c(prices, prices2)
dekalbtable <- cbind(addresses, prices)
# Chunk 21
cook_df <- as.data.frame(cooktable)
dekalb_df <- as.data.frame(dekalbtable)
dupage_df <- as.data.frame(dupagetable)
lake_df <- as.data.frame(laketable)
will_df <- as.data.frame(willtable)
# Chunk 22
cook_df$county <- "Cook"
dekalb_df$county <- "DeKalb"
dupage_df$county <- "DuPage"
lake_df$county <- "Lake"
will_df$county <- "Will"
# Chunk 23
library(dplyr)
chicago_df <- bind_rows(cook_df, dekalb_df, dupage_df, lake_df, will_df)
# Chunk 24
chicago_df$addresses <- gsub(",\\s*\\d+\\s*,\\s*", ", ", chicago_df$addresses)
cities <- c("Chicago", "Addison", "Naperville", "Zion")
city_pattern <- paste(cities, collapse = "|")
regex_pattern <- paste0(", [^,]*?, (", city_pattern, "), ([A-Z]{2} \\d{5})$")
chicago_df$addresses <- gsub(regex_pattern, ", \\1, \\2", chicago_df$addresses)
#chicago_df[1, "addresses"] <- "6218 S Indiana Ave, Chicago, IL 60637"
#chicago_df[7, "addresses"] <- "5038 W Washington Blvd, Chicago, IL 60644"
#chicago_df[14, "addresses"] <- "3614 W Augusta Blvd, Chicago, IL 60651"
#chicago_df[15, "addresses"] <- "1416 S Karlov Ave, Chicago, IL 60623"
#chicago_df[31, "addresses"] <- "226 N Pine Ave, Chicago, IL 60644"
#chicago_df[32, "addresses"] <- "8211 S Ellis Ave, Chicago, IL 60619"
#chicago_df[40, "addresses"] <- "350 N State St, Addison, IL 60101"
#chicago_df[44, "addresses"] <- "302 W Dale Dr, Addison, IL 60101"
library(tidygeocoder)
chicago_df_geo <- geocode(chicago_df, address = addresses, lat = "lat", long = "long")
# Chunk 25
#This address didn't geocode so I'm adding it manually
chicago_df_geo[60, "lat"] <- 42.26874
chicago_df_geo[60, "long"] <- -88.19455
# Chunk 26
library(sf)
library(units)
library(dplyr)
chicago_sf <- chicago_df_geo %>%
st_as_sf(coords = c("long", "lat"), crs = 4326)
tmap_mode(mode="plot")
library(tidyverse)
library(tidycensus)
library(tigris)
library(sf)
library(tmap)
library(RColorBrewer)
tmap_mode(mode="plot")
#ensure code folds
knitr::opts_chunk$set(class.source = "foldable")
#load libraries
library(tidyverse)
library(igraph)
library(ggraph)
library(sf)
library(tmap)
library(spdep)
library(sfdep)
#library(concaveman)
#library(RColorBrewer)
library(lubridate)
library(sjmisc)
# set maps to interactive
tmap_mode(mode = "view")
tmap_options(basemaps = NULL)
setwd("~/Course_Work/GEOG_456/DEV/GEOG_456/assignment5/data")
s <- read_sf("searches4326.geojson")
sp <- read_sf("sp.geojson")
View(sp)
sp <- sp %>% mutate(SQ_NO = (SQ_NO - 1))
write_sf(sp, "sp.geojson")
write_sf(sp, "sp.geojson")
